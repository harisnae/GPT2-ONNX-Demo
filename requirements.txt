# -------------------------------------------------
# Core ðŸ¤— libraries (used directly in the notebook)
# -------------------------------------------------
transformers          # WhisperProcessor, pipeline, GenerationConfig, â€¦
huggingface_hub       # snapshot_download, repo handling
sentencepiece         # Tokenizer & modelâ€‘format utilities

# -------------------------------------------------
# Optimum + ONNX Runtime (CPU wheel â€“ the notebook will later install the GPU wheel if needed)
# -------------------------------------------------
optimum[onnxruntime]  # Optimum wrapper + the CPU ONNX Runtime wheel

# -------------------------------------------------
# ONNX Runtime (CPU & GPU builds â€“ the same version number)
# -------------------------------------------------
onnxruntime
onnxruntime-gpu

# If you want GPU acceleration you can install the GPU build manually:
#   pip install onnxruntime-gpu
# (the notebook installs the correct build automatically, but listing it here
#  makes the file selfâ€‘contained for offline installs.)

# -------------------------------------------------
# PyTorch (only needed for the CUDAâ€‘availability check)
# -------------------------------------------------
torch                  # CPUâ€‘only or GPUâ€‘enabled builds â€“ pip will pull the right wheel

# -------------------------------------------------
# Optional â€“ pin exact versions (uncomment & replace with numbers if you need a reproducible freeze)
# -------------------------------------------------
# transformers==4.44.0
# huggingface_hub==0.24.0
# optimum==1.22.0
# onnxruntime==1.18.1          # or onnxruntimeâ€‘gpu==1.18.1 for GPU
# torch==2.4.0
